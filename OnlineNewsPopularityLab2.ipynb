{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Online News Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Created by Phillip Efthimion, Scott Payne, Gino Varghese and John Blevins**\n",
    "\n",
    "*MSDS 7331 Data Mining - Section 403 - Lab 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 1\t\n",
    "Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "Phillip\n",
    "* Copy data preparation steps\n",
    "* Copy Dimension Reduction and Scaling from Minilab (PCA)- this pickup up in Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 2\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "Phillip\n",
    "* Describe how we created Popularity\n",
    "* Insert chart with attributes and meaning from lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### including data points for evaluation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7346 entries, 4 to 39639\n",
      "Data columns (total 54 columns):\n",
      "n_tokens_title                  7346 non-null float64\n",
      "n_tokens_content                7346 non-null float64\n",
      "n_unique_tokens                 7346 non-null float64\n",
      "n_non_stop_words                7346 non-null float64\n",
      "n_non_stop_unique_tokens        7346 non-null float64\n",
      "num_hrefs                       7346 non-null float64\n",
      "num_self_hrefs                  7346 non-null float64\n",
      "num_imgs                        7346 non-null float64\n",
      "num_videos                      7346 non-null float64\n",
      "average_token_length            7346 non-null float64\n",
      "num_keywords                    7346 non-null float64\n",
      "kw_min_min                      7346 non-null float64\n",
      "kw_max_min                      7346 non-null float64\n",
      "kw_avg_min                      7346 non-null float64\n",
      "kw_min_max                      7346 non-null float64\n",
      "kw_max_max                      7346 non-null float64\n",
      "kw_avg_max                      7346 non-null float64\n",
      "kw_min_avg                      7346 non-null float64\n",
      "kw_max_avg                      7346 non-null float64\n",
      "kw_avg_avg                      7346 non-null float64\n",
      "self_reference_min_shares       7346 non-null float64\n",
      "self_reference_max_shares       7346 non-null float64\n",
      "self_reference_avg_sharess      7346 non-null float64\n",
      "monday                          7346 non-null float64\n",
      "tuesday                         7346 non-null float64\n",
      "wednesday                       7346 non-null float64\n",
      "thursday                        7346 non-null float64\n",
      "friday                          7346 non-null float64\n",
      "saturday                        7346 non-null float64\n",
      "sunday                          7346 non-null float64\n",
      "weekend                         7346 non-null float64\n",
      "LDA_00                          7346 non-null float64\n",
      "LDA_01                          7346 non-null float64\n",
      "LDA_02                          7346 non-null float64\n",
      "LDA_03                          7346 non-null float64\n",
      "LDA_04                          7346 non-null float64\n",
      "global_subjectivity             7346 non-null float64\n",
      "global_sentiment_polarity       7346 non-null float64\n",
      "global_rate_positive_words      7346 non-null float64\n",
      "global_rate_negative_words      7346 non-null float64\n",
      "rate_positive_words             7346 non-null float64\n",
      "rate_negative_words             7346 non-null float64\n",
      "avg_positive_polarity           7346 non-null float64\n",
      "min_positive_polarity           7346 non-null float64\n",
      "max_positive_polarity           7346 non-null float64\n",
      "avg_negative_polarity           7346 non-null float64\n",
      "min_negative_polarity           7346 non-null float64\n",
      "max_negative_polarity           7346 non-null float64\n",
      "title_subjectivity              7346 non-null float64\n",
      "title_sentiment_polarity        7346 non-null float64\n",
      "abs_title_subjectivity          7346 non-null float64\n",
      "abs_title_sentiment_polarity    7346 non-null float64\n",
      "shares                          7346 non-null int64\n",
      "popularity                      7346 non-null int64\n",
      "dtypes: float64(52), int64(2)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Import and Configure Required Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "plt.rcParams['figure.figsize']=(15,10)\n",
    "\n",
    "# Read Online News Data\n",
    "df = pd.read_csv('data/OnlineNewsPopularity.csv')\n",
    "\n",
    "# Correct Column Names by Removing Leading Space\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# Rename Columns for Ease of Display\n",
    "df = df.rename(columns={'weekday_is_monday': 'monday', 'weekday_is_tuesday': 'tuesday', 'weekday_is_wednesday': 'wednesday', 'weekday_is_thursday': 'thursday', 'weekday_is_friday': 'friday', 'weekday_is_saturday': 'saturday', 'weekday_is_sunday': 'sunday', 'is_weekend': 'weekend'})\n",
    "df = df.rename(columns={'data_channel_is_lifestyle':'lifestyle', 'data_channel_is_entertainment':'entertainment', 'data_channel_is_bus':'business', 'data_channel_is_socmed':'social_media', 'data_channel_is_tech':'technology', 'data_channel_is_world':'world'})\n",
    "\n",
    "# Encode a new \"popular\" column based on the # of shares \n",
    "# \"popular\" = 1 and \"not popular\" to 0.\n",
    "df['popularity'] = pd.qcut(df['shares'].values, 2, labels=[0,1])\n",
    "df.popularity = df.popularity.astype(np.int)\n",
    "\n",
    "# Take a subset of the data related to Technology News Articles\n",
    "dfsubset = df.loc[df['technology'] == 1]\n",
    "\n",
    "# Reassign to New Variable and remove Columns which aren't needed\n",
    "df_imputed = dfsubset\n",
    "del df_imputed['url']\n",
    "#del df_imputed['shares']\n",
    "del df_imputed['timedelta']\n",
    "del df_imputed['lifestyle']\n",
    "del df_imputed['entertainment']\n",
    "del df_imputed['business']\n",
    "del df_imputed['social_media']\n",
    "del df_imputed['technology']\n",
    "del df_imputed['world']\n",
    "\n",
    "# Display Dataframe Structure\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1\n",
    "Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "Phillip\n",
    "* Calculating Acc, Rec, F-measure, Negative Predictive Value, Specificity etc... from confusion matrix\n",
    "\n",
    "Gino - Saturday Afternoon\n",
    "\n",
    "Final attributes from PCA:\n",
    "['n_tokens_content', 'n_unique_tokens', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_self_hrefs', 'kw_min_min', 'kw_max_avg', 'kw_avg_avg', 'weekend', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_negative_words']\n",
    "\n",
    "* 2 Tasks: Popularity (classification) and Share # (Regression)\n",
    "* Regression - Linear, Lasso, Ridge\n",
    "* Classification - Logistic Regression, K nearest Neighbors, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import metrics to collect metrics for each modelS\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "#Separating data sets for each task\n",
    "\n",
    "#task 1 Popularity Classification\n",
    "df_task1 = df_imputed[['popularity','n_tokens_content', 'n_unique_tokens', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_self_hrefs', 'kw_min_min', 'kw_max_avg', 'kw_avg_avg', 'weekend', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_negative_words']].copy()\n",
    "\n",
    "\n",
    "#task 2 Shares Regression\n",
    "df_task2 = df_imputed\n",
    "df_task2 = df_task2.drop(['popularity'],axis=1)\n",
    "\n",
    "\n",
    "#Create list to store datapoints for accuracy, precision, recall, F-measure from each of the model\n",
    "accuracy_dp = []\n",
    "precision_dp = []\n",
    "recall_dp = []\n",
    "fmeasure_dp = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2\n",
    "Choose the method you will use for dividing your data into training and\n",
    "testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "Gino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=True, shuffle=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratified 10 folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'popularity' in df_task1:\n",
    "    y = df_task1['popularity'].values # get the labels we want\n",
    "    del df_task1['popularity'] # get rid of the class label\n",
    "    X = df_task1.values # use everything else to predict!\n",
    "    \n",
    "\n",
    "yhat = np.zeros(y.shape)\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)\n",
    "                         \n",
    "print(cv_object)\n",
    "cv_object.get_n_splits(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3\n",
    "Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "\n",
    "Gino\n",
    "\n",
    "* For Regression make sure popularity field is excluded and for classification make sure Share # is excluded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Popularity (classification) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 62.6736%\n",
      "Recall of the model: 86.4648%\n",
      "Precision of the model: 63.6548%\n",
      "F-measure of the model: 73.3268%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "#penalty is set to default, which is 12.\n",
    "lr_task1 = LogisticRegression(C=1.0, class_weight=None)\n",
    "\n",
    "# iterate through and get predictions for each row in yhat\n",
    "for train, test in cv_object.split(X,y):\n",
    "    lr_task1.fit(X[train],y[train])\n",
    "    yhat[test] = lr_task1.predict(X[test])\n",
    "\n",
    "#evaluation metrics   \n",
    "acc = mt.accuracy_score(y, yhat)\n",
    "recall = mt.recall_score(y, yhat)\n",
    "precision = mt.precision_score(y, yhat)\n",
    "f = mt.f1_score(y, yhat)\n",
    "\n",
    "\n",
    "#adding evaluation metrics to list for further analysis between models\n",
    "accuracy_dp.append(acc)\n",
    "recall_dp.append(recall)\n",
    "precision_dp.append(precision)\n",
    "fmeasure_dp.append(f)\n",
    "\n",
    "\n",
    "\n",
    "#results in percentage\n",
    "print(\"Accuracy of the model: {0:.4f}%\".format(acc*100))\n",
    "print(\"Recall of the model: {0:.4f}%\".format(recall*100))\n",
    "print(\"Precision of the model: {0:.4f}%\".format(precision*100))\n",
    "print(\"F-measure of the model: {0:.4f}%\".format(f*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K nearest Neighbors, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy returned by the classifier is: 62.6194% with k value of: 27\n"
     ]
    }
   ],
   "source": [
    "# As a team we setup KNN Classifier iterator to to determine the accurate number of nearest neighbours\n",
    "# the highest iterations we are planning was 30, to get the best accuracy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "counter = 1;\n",
    "best_accuracy= 0.0;\n",
    "kVal = 1;\n",
    "while counter <= 30:\n",
    "    clf = KNeighborsClassifier(n_neighbors=counter)\n",
    "    clf.fit(X[train],y[train])\n",
    "    acc = clf.score(X[test],y[test]);\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc;\n",
    "        kVal = counter;\n",
    "    counter += 1;\n",
    "neighbors=kVal\n",
    "print(\"Best Accuracy returned by the classifier is: {0:.4f}%\".format(best_accuracy*100),\"with k value of:\",kVal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k value: 27\n",
      "Accuracy of the model: 61.1353%\n",
      "Recall of the model: 78.7337%\n",
      "Precision of the model: 64.0299%\n",
      "F-measure of the model: 70.6245%\n"
     ]
    }
   ],
   "source": [
    "# Actual trainning and testing of the model begins\n",
    "print(\"The best k value:\", neighbors)\n",
    "knn_task1 = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "\n",
    "# iterate through and get predictions for each row in yhat\n",
    "for train, test in cv_object.split(X,y):\n",
    "    knn_task1.fit(X[train],y[train])\n",
    "    yhat[test] = knn_task1.predict(X[test])\n",
    "\n",
    "#evaluation metrics   \n",
    "acc = mt.accuracy_score(y, yhat)\n",
    "recall = mt.recall_score(y, yhat)\n",
    "precision = mt.precision_score(y, yhat)\n",
    "f = mt.f1_score(y, yhat)\n",
    "\n",
    "#adding evaluation metrics to list for further analysis between models\n",
    "accuracy_dp.append(acc)\n",
    "recall_dp.append(recall)\n",
    "precision_dp.append(precision)\n",
    "fmeasure_dp.append(f)\n",
    "\n",
    "\n",
    "\n",
    "#results in percentage\n",
    "print(\"Accuracy of the model: {0:.4f}%\".format(acc*100))\n",
    "print(\"Recall of the model: {0:.4f}%\".format(recall*100))\n",
    "print(\"Precision of the model: {0:.4f}%\".format(precision*100))\n",
    "print(\"F-measure of the model: {0:.4f}%\".format(f*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 63.7898%\n",
      "Recall of the model: 78.2519%\n",
      "Precision of the model: 66.5821%\n",
      "F-measure of the model: 71.9468%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "rf_task1 = RandomForestClassifier(n_estimators=150, n_jobs=-1)\n",
    "\n",
    "# iterate through and get predictions for each row in yhat\n",
    "for train, test in cv_object.split(X,y):\n",
    "    rf_task1.fit(X[train],y[train])\n",
    "    yhat[test] = rf_task1.predict(X[test])\n",
    "\n",
    "#evaluation metrics   \n",
    "acc = mt.accuracy_score(y, yhat)\n",
    "recall = mt.recall_score(y, yhat)\n",
    "precision = mt.precision_score(y, yhat)\n",
    "f = mt.f1_score(y, yhat)\n",
    "\n",
    "#adding evaluation metrics to list for further analysis between models\n",
    "accuracy_dp.append(acc)\n",
    "recall_dp.append(recall)\n",
    "precision_dp.append(precision)\n",
    "fmeasure_dp.append(f)\n",
    "\n",
    "\n",
    "#results in percentage\n",
    "print(\"Accuracy of the model: {0:.4f}%\".format(acc*100))\n",
    "print(\"Recall of the model: {0:.4f}%\".format(recall*100))\n",
    "print(\"Precision of the model: {0:.4f}%\".format(precision*100))\n",
    "print(\"F-measure of the model: {0:.4f}%\".format(f*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Number of Shares (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -9.52261715e-14  -1.67270711e-15   1.35672740e-11  -3.95929557e-05\n",
      "   3.13019922e-12  -1.57512892e-14  -9.46716663e-14   2.71560552e-13\n",
      "  -6.90114632e-13   1.76493992e-12   1.65754563e-13  -2.50654532e-14\n",
      "   5.62050406e-16  -3.05593224e-15  -6.32252497e-16  -1.38777878e-17\n",
      "   8.67361738e-17   8.96852037e-16   7.56339436e-16  -2.68535194e-15\n",
      "   4.53803661e-15  -2.55698240e-15   1.26287869e-15   6.45919445e-11\n",
      "   6.50679044e-11   6.46861348e-11   6.51480398e-11   6.46991625e-11\n",
      "  -5.60190902e-12  -5.65230393e-12   7.07901303e-11   2.41419189e-09\n",
      "   2.40959795e-09   2.40929515e-09   2.41110039e-09   2.41054913e-09\n",
      "  -4.54589123e-12  -1.27238738e-12  -6.36364243e-12  -2.12458781e-11\n",
      "   3.95929231e-05   3.95929204e-05   3.69534279e-12  -7.30283146e-13\n",
      "  -5.50469524e-13   3.92338195e-12  -3.93832567e-12   2.61962465e-12\n",
      "  -6.84243545e-13  -1.91229133e-13  -4.71466756e-13   2.35997220e-13\n",
      "   1.00000000e+00]\n",
      "Mean squared error: 0.00\n",
      "Variance score: 1.00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-32b9aa0eeb59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# Plot outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiabetes_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiabetes_y_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m plt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n\u001b[1;32m     43\u001b[0m          linewidth=3)\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3433\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3434\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3435\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3437\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1890\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1891\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1892\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1893\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sam/anaconda3/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3956\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3958\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAAJDCAYAAACc1iwFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAEAD4g0AAKAB8QYAANCAeAMAAGjg/wDk6+UCNmpbKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f65004c96d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#stratified 10 folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#df_task2.info()\n",
    "#del df_task2['popularity']\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "\n",
    "# Load the diabetes dataset\n",
    "#diabetes = datasets.load_diabetes()\n",
    "\n",
    "\n",
    "# Use only one feature\n",
    "#diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = df_task2[:-20]\n",
    "diabetes_X_test = df_task2[-20:]\n",
    "\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = df_task2.shares[:-20]\n",
    "diabetes_y_test = df_task2.shares[-20:]\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % np.mean((regr.predict(diabetes_X_test) - diabetes_y_test) ** 2))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(diabetes_X_test, diabetes_y_test))\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test, diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test, regr.predict(diabetes_X_test), color='blue',\n",
    "         linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4\n",
    "Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "John\n",
    "* For Regression just compare attributes selected which are significantly\n",
    "* For Classification determine accuracy, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 5\n",
    "Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniquesâ€”be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "\n",
    "John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 6\n",
    "Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "\n",
    "Scott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work\n",
    "\n",
    "You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?\n",
    "\n",
    "Scott\n",
    "\n",
    "Possible Analysis:\n",
    "\n",
    "Deep Learning\n",
    "\n",
    "Neaural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

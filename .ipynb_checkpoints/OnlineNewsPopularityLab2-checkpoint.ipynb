{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Online News Popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Created by Phillip Efthimion, Scott Payne, Gino Varghese and John Blevins**\n",
    "\n",
    "*MSDS 7331 Data Mining - Section 403 - Lab 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 1\t\n",
    "Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "Phillip\n",
    "* Copy data preparation steps\n",
    "* Copy Dimension Reduction and Scaling from Minilab (PCA)- this pickup up in Modeling and Evaluation 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation Part 2\n",
    "Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "Phillip\n",
    "* Describe how we created Popularity\n",
    "* Insert chart with attributes and meaning from lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### including data points for evaluation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7346 entries, 4 to 39639\n",
      "Data columns (total 54 columns):\n",
      "n_tokens_title                  7346 non-null float64\n",
      "n_tokens_content                7346 non-null float64\n",
      "n_unique_tokens                 7346 non-null float64\n",
      "n_non_stop_words                7346 non-null float64\n",
      "n_non_stop_unique_tokens        7346 non-null float64\n",
      "num_hrefs                       7346 non-null float64\n",
      "num_self_hrefs                  7346 non-null float64\n",
      "num_imgs                        7346 non-null float64\n",
      "num_videos                      7346 non-null float64\n",
      "average_token_length            7346 non-null float64\n",
      "num_keywords                    7346 non-null float64\n",
      "kw_min_min                      7346 non-null float64\n",
      "kw_max_min                      7346 non-null float64\n",
      "kw_avg_min                      7346 non-null float64\n",
      "kw_min_max                      7346 non-null float64\n",
      "kw_max_max                      7346 non-null float64\n",
      "kw_avg_max                      7346 non-null float64\n",
      "kw_min_avg                      7346 non-null float64\n",
      "kw_max_avg                      7346 non-null float64\n",
      "kw_avg_avg                      7346 non-null float64\n",
      "self_reference_min_shares       7346 non-null float64\n",
      "self_reference_max_shares       7346 non-null float64\n",
      "self_reference_avg_sharess      7346 non-null float64\n",
      "monday                          7346 non-null float64\n",
      "tuesday                         7346 non-null float64\n",
      "wednesday                       7346 non-null float64\n",
      "thursday                        7346 non-null float64\n",
      "friday                          7346 non-null float64\n",
      "saturday                        7346 non-null float64\n",
      "sunday                          7346 non-null float64\n",
      "weekend                         7346 non-null float64\n",
      "LDA_00                          7346 non-null float64\n",
      "LDA_01                          7346 non-null float64\n",
      "LDA_02                          7346 non-null float64\n",
      "LDA_03                          7346 non-null float64\n",
      "LDA_04                          7346 non-null float64\n",
      "global_subjectivity             7346 non-null float64\n",
      "global_sentiment_polarity       7346 non-null float64\n",
      "global_rate_positive_words      7346 non-null float64\n",
      "global_rate_negative_words      7346 non-null float64\n",
      "rate_positive_words             7346 non-null float64\n",
      "rate_negative_words             7346 non-null float64\n",
      "avg_positive_polarity           7346 non-null float64\n",
      "min_positive_polarity           7346 non-null float64\n",
      "max_positive_polarity           7346 non-null float64\n",
      "avg_negative_polarity           7346 non-null float64\n",
      "min_negative_polarity           7346 non-null float64\n",
      "max_negative_polarity           7346 non-null float64\n",
      "title_subjectivity              7346 non-null float64\n",
      "title_sentiment_polarity        7346 non-null float64\n",
      "abs_title_subjectivity          7346 non-null float64\n",
      "abs_title_sentiment_polarity    7346 non-null float64\n",
      "shares                          7346 non-null int64\n",
      "popularity                      7346 non-null int64\n",
      "dtypes: float64(52), int64(2)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "# Import and Configure Required Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import datetime\n",
    "warnings.simplefilter('ignore', DeprecationWarning)\n",
    "plt.rcParams['figure.figsize']=(15,10)\n",
    "\n",
    "# Read Online News Data\n",
    "df = pd.read_csv('data/OnlineNewsPopularity.csv')\n",
    "\n",
    "# Correct Column Names by Removing Leading Space\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# Rename Columns for Ease of Display\n",
    "df = df.rename(columns={'weekday_is_monday': 'monday', 'weekday_is_tuesday': 'tuesday', 'weekday_is_wednesday': 'wednesday', 'weekday_is_thursday': 'thursday', 'weekday_is_friday': 'friday', 'weekday_is_saturday': 'saturday', 'weekday_is_sunday': 'sunday', 'is_weekend': 'weekend'})\n",
    "df = df.rename(columns={'data_channel_is_lifestyle':'lifestyle', 'data_channel_is_entertainment':'entertainment', 'data_channel_is_bus':'business', 'data_channel_is_socmed':'social_media', 'data_channel_is_tech':'technology', 'data_channel_is_world':'world'})\n",
    "\n",
    "# Encode a new \"popular\" column based on the # of shares \n",
    "# \"popular\" = 1 and \"not popular\" to 0.\n",
    "df['popularity'] = pd.qcut(df['shares'].values, 2, labels=[0,1])\n",
    "df.popularity = df.popularity.astype(np.int)\n",
    "\n",
    "# Take a subset of the data related to Technology News Articles\n",
    "dfsubset = df.loc[df['technology'] == 1]\n",
    "\n",
    "# Reassign to New Variable and remove Columns which aren't needed\n",
    "df_imputed = dfsubset\n",
    "del df_imputed['url']\n",
    "#del df_imputed['shares']\n",
    "del df_imputed['timedelta']\n",
    "del df_imputed['lifestyle']\n",
    "del df_imputed['entertainment']\n",
    "del df_imputed['business']\n",
    "del df_imputed['social_media']\n",
    "del df_imputed['technology']\n",
    "del df_imputed['world']\n",
    "\n",
    "# Display Dataframe Structure\n",
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 1\n",
    "Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions.\n",
    "\n",
    "Phillip\n",
    "* Calculating Acc, Rec, F-measure, Negative Predictive Value, Specificity etc... from confusion matrix\n",
    "\n",
    "Gino - Saturday Afternoon\n",
    "\n",
    "Final attributes from PCA:\n",
    "['n_tokens_content', 'n_unique_tokens', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_self_hrefs', 'kw_min_min', 'kw_max_avg', 'kw_avg_avg', 'weekend', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_negative_words']\n",
    "\n",
    "* 2 Tasks: Popularity (classification) and Share # (Regression)\n",
    "* Regression - Linear, Lasso, Ridge\n",
    "* Classification - Logistic Regression, K nearest Neighbors, Random Forest\n",
    "\n",
    "\n",
    "* Accuracy\n",
    "Accuracy : the proportion of the total number of predictions that were correct.\n",
    "(a + d) / (a + b + c + d)\n",
    "\n",
    "* Precision\n",
    "Positive Predictive Value or Precision : the proportion of positive cases that were correctly identified.\n",
    "a / (a + b)\n",
    "Negative Predictive Value : the proportion of negative cases that were correctly identified.\n",
    "d / (c + d)\n",
    "\n",
    "\n",
    "\n",
    "* Recall\n",
    "Recall : the proportion of actual positive cases which are correctly identified.\n",
    "a / (a + c)\n",
    "\n",
    "Recall could be our primary go to metric as it evaluates the context of identifying online articles which fall between High to Medium popularity or Medium to Low popularity(ex. articles that are on the border line between popularity classes)\n",
    "\n",
    "* F-Measure\n",
    "the proportion of actual negative cases which are correctly identified.\n",
    "d / (b + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import metrics to collect metrics for each modelS\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "#Separating data sets for each task\n",
    "\n",
    "#task 1 Popularity Classification\n",
    "df_task1 = df_imputed[['popularity','n_tokens_content', 'n_unique_tokens', 'n_non_stop_unique_tokens', 'num_hrefs', 'num_self_hrefs', 'kw_min_min', 'kw_max_avg', 'kw_avg_avg', 'weekend', 'global_rate_positive_words', 'global_rate_negative_words', 'rate_negative_words']].copy()\n",
    "\n",
    "\n",
    "#task 2 Shares Regression\n",
    "df_task2 = df_imputed\n",
    "df_task2 = df_task2.drop(['popularity'],axis=1)\n",
    "\n",
    "\n",
    "#Create list to store datapoints for accuracy, precision, recall, F-measure from each of the model\n",
    "accuracy_dp = []\n",
    "precision_dp = []\n",
    "recall_dp = []\n",
    "fmeasure_dp = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 2\n",
    "Choose the method you will use for dividing your data into training and\n",
    "testing splits (i.e., are you using Stratified 10-fold cross validation? Why?). Explain why\n",
    "your chosen method is appropriate or use more than one method as appropriate. For example, if you are using time series data then you should be using continuous training and testing sets across time.\n",
    "\n",
    "Gino\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our approach we will be using Stratified 10-Fold Cross Validation for our analysis. \n",
    "This approach will provide our analysis with the high degree of precision, it is most appropriate for us to use in our analysis due to the characteristic of our data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=10, random_state=True, shuffle=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stratified 10 folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'popularity' in df_task1:\n",
    "    y = df_task1['popularity'].values # get the labels we want\n",
    "    del df_task1['popularity'] # get rid of the class label\n",
    "    X = df_task1.values # use everything else to predict!\n",
    "    \n",
    "\n",
    "yhat = np.zeros(y.shape)\n",
    "\n",
    "cv_object = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)\n",
    "                         \n",
    "print(cv_object)\n",
    "cv_object.get_n_splits(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 3\n",
    "Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!\n",
    "\n",
    "Gino\n",
    "\n",
    "* For Regression make sure popularity field is excluded and for classification make sure Share # is excluded!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 : Popularity (classification) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 62.6736%\n",
      "Recall of the model: 86.4648%\n",
      "Precision of the model: 63.6548%\n",
      "F-measure of the model: 73.3268%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "#penalty is set to default, which is 12.\n",
    "lr_task1 = LogisticRegression(C=1.0, class_weight=None)\n",
    "\n",
    "# iterate through and get predictions for each row in yhat\n",
    "for train, test in cv_object.split(X,y):\n",
    "    lr_task1.fit(X[train],y[train])\n",
    "    yhat[test] = lr_task1.predict(X[test])\n",
    "\n",
    "#evaluation metrics   \n",
    "acc = mt.accuracy_score(y, yhat)\n",
    "recall = mt.recall_score(y, yhat)\n",
    "precision = mt.precision_score(y, yhat)\n",
    "f = mt.f1_score(y, yhat)\n",
    "\n",
    "\n",
    "#adding evaluation metrics to list for further analysis between models\n",
    "accuracy_dp.append(acc)\n",
    "recall_dp.append(recall)\n",
    "precision_dp.append(precision)\n",
    "fmeasure_dp.append(f)\n",
    "\n",
    "\n",
    "\n",
    "#results in percentage\n",
    "print(\"Accuracy of the model: {0:.4f}%\".format(acc*100))\n",
    "print(\"Recall of the model: {0:.4f}%\".format(recall*100))\n",
    "print(\"Precision of the model: {0:.4f}%\".format(precision*100))\n",
    "print(\"F-measure of the model: {0:.4f}%\".format(f*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K nearest Neighbors, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy returned by the classifier is: 62.6194% with k value of: 27\n"
     ]
    }
   ],
   "source": [
    "# As a team we setup KNN Classifier iterator to to determine the accurate number of nearest neighbours\n",
    "# the highest iterations we are planning was 30, to get the best accuracy\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "counter = 1;\n",
    "best_accuracy= 0.0;\n",
    "kVal = 1;\n",
    "while counter <= 30:\n",
    "    clf = KNeighborsClassifier(n_neighbors=counter)\n",
    "    clf.fit(X[train],y[train])\n",
    "    acc = clf.score(X[test],y[test]);\n",
    "    if acc > best_accuracy:\n",
    "        best_accuracy = acc;\n",
    "        kVal = counter;\n",
    "    counter += 1;\n",
    "neighbors=kVal\n",
    "print(\"Best Accuracy returned by the classifier is: {0:.4f}%\".format(best_accuracy*100),\"with k value of:\",kVal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best k value: 27\n",
      "Accuracy of the model: 61.1353%\n",
      "Recall of the model: 78.7337%\n",
      "Precision of the model: 64.0299%\n",
      "F-measure of the model: 70.6245%\n"
     ]
    }
   ],
   "source": [
    "# Actual trainning and testing of the model begins\n",
    "print(\"The best k value:\", neighbors)\n",
    "knn_task1 = KNeighborsClassifier(n_neighbors=neighbors)\n",
    "\n",
    "# iterate through and get predictions for each row in yhat\n",
    "for train, test in cv_object.split(X,y):\n",
    "    knn_task1.fit(X[train],y[train])\n",
    "    yhat[test] = knn_task1.predict(X[test])\n",
    "\n",
    "#evaluation metrics   \n",
    "acc = mt.accuracy_score(y, yhat)\n",
    "recall = mt.recall_score(y, yhat)\n",
    "precision = mt.precision_score(y, yhat)\n",
    "f = mt.f1_score(y, yhat)\n",
    "\n",
    "#adding evaluation metrics to list for further analysis between models\n",
    "accuracy_dp.append(acc)\n",
    "recall_dp.append(recall)\n",
    "precision_dp.append(precision)\n",
    "fmeasure_dp.append(f)\n",
    "\n",
    "\n",
    "\n",
    "#results in percentage\n",
    "print(\"Accuracy of the model: {0:.4f}%\".format(acc*100))\n",
    "print(\"Recall of the model: {0:.4f}%\".format(recall*100))\n",
    "print(\"Precision of the model: {0:.4f}%\".format(precision*100))\n",
    "print(\"F-measure of the model: {0:.4f}%\".format(f*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model: 63.7490%\n",
      "Recall of the model: 77.9995%\n",
      "Precision of the model: 66.6144%\n",
      "F-measure of the model: 71.8588%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get a handle to the classifier object, which defines the type\n",
    "rf_task1 = RandomForestClassifier(n_estimators=150, n_jobs=-1)\n",
    "\n",
    "# iterate through and get predictions for each row in yhat\n",
    "for train, test in cv_object.split(X,y):\n",
    "    rf_task1.fit(X[train],y[train])\n",
    "    yhat[test] = rf_task1.predict(X[test])\n",
    "\n",
    "#evaluation metrics   \n",
    "acc = mt.accuracy_score(y, yhat)\n",
    "recall = mt.recall_score(y, yhat)\n",
    "precision = mt.precision_score(y, yhat)\n",
    "f = mt.f1_score(y, yhat)\n",
    "\n",
    "#adding evaluation metrics to list for further analysis between models\n",
    "accuracy_dp.append(acc)\n",
    "recall_dp.append(recall)\n",
    "precision_dp.append(precision)\n",
    "fmeasure_dp.append(f)\n",
    "\n",
    "\n",
    "#results in percentage\n",
    "print(\"Accuracy of the model: {0:.4f}%\".format(acc*100))\n",
    "print(\"Recall of the model: {0:.4f}%\".format(recall*100))\n",
    "print(\"Precision of the model: {0:.4f}%\".format(precision*100))\n",
    "print(\"F-measure of the model: {0:.4f}%\".format(f*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 : Number of Shares (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.cross_validation.KFold(n=7346, n_folds=10, shuffle=False, random_state=None)\n",
      "Method: Simple Linear Regression\n",
      "Root Mean Square Error on training: 8918.1095\n",
      "Root Mean Square Error on 10-fold CV: 9037.6769\n",
      "-0.115917865309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n",
    "# we want to predict the X and y data as follows:\n",
    "if 'shares' in df_task2:\n",
    "    y = df_task2['shares'].values # get the labels we want\n",
    "    del df_task2['shares'] # get rid of the class label\n",
    "    X = df_task2.values # use everything else to predict!\n",
    "\n",
    "#X =  np.array([np.concatenate((v,[1])) for v in df_task2.values])\n",
    "\n",
    "yhat = np.zeros(y.shape)\n",
    "#cv_object = StratifiedKFold(n_splits=10, random_state=True, shuffle=True)\n",
    "cv_object = KFold(len(X),n_folds=10)\n",
    "\n",
    "print(cv_object)\n",
    "#cv_object.get_n_splits(X,y)\n",
    "\n",
    "lr_task2 = LinearRegression()\n",
    "\n",
    "xval_error = 0\n",
    "for train, test in cv_object:\n",
    "    lr_task2.fit(X[train], y[train])\n",
    "    p = lr_task2.predict(X[test])\n",
    "    e = p-y[test]\n",
    "    xval_error += np.dot(e,e)\n",
    "\n",
    "rmse_10cv = np.sqrt(xval_error/len(X))\n",
    "\n",
    "\n",
    "\n",
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('Root Mean Square Error on training: %.4f' %rmse_train)\n",
    "print('Root Mean Square Error on 10-fold CV: %.4f' %rmse_10cv)\n",
    "print(mt.r2_score(y,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression\n",
      "Root Mean Square Error on training: 8918.1095\n",
      "Root Mean Square Error on 10-fold CV: 9031.1295\n",
      "-0.115917865309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "lr_task2 = Lasso(fit_intercept=True,alpha=0.5)\n",
    "\n",
    "xval_error = 0\n",
    "for train, test in cv_object:\n",
    "    lr_task2.fit(X[train], y[train])\n",
    "    p = lr_task2.predict(X[test])\n",
    "    e = p-y[test]\n",
    "    xval_error += np.dot(e,e)\n",
    "\n",
    "rmse_10cv = np.sqrt(xval_error/len(X))\n",
    "\n",
    "\n",
    "\n",
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('Root Mean Square Error on training: %.4f' %rmse_train)\n",
    "print('Root Mean Square Error on 10-fold CV: %.4f' %rmse_10cv)\n",
    "print(mt.r2_score(y,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression\n",
      "Root Mean Square Error on training: 8918.1095\n",
      "Root Mean Square Error on 10-fold CV: 9031.5093\n",
      "-0.115917865309\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "lr_task2 = Ridge(fit_intercept=True,alpha=0.5)\n",
    "\n",
    "xval_error = 0\n",
    "for train, test in cv_object:\n",
    "    lr_task2.fit(X[train], y[train])\n",
    "    p = lr_task2.predict(X[test])\n",
    "    e = p-y[test]\n",
    "    xval_error += np.dot(e,e)\n",
    "\n",
    "rmse_10cv = np.sqrt(xval_error/len(X))\n",
    "\n",
    "\n",
    "\n",
    "method_name = 'Simple Linear Regression'\n",
    "print('Method: %s' %method_name)\n",
    "print('Root Mean Square Error on training: %.4f' %rmse_train)\n",
    "print('Root Mean Square Error on 10-fold CV: %.4f' %rmse_10cv)\n",
    "print(mt.r2_score(y,yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 4\n",
    "Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "John\n",
    "* For Regression just compare attributes selected which are significantly\n",
    "* For Classification determine accuracy, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 5\n",
    "Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniquesâ€”be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course.\n",
    "\n",
    "John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation 6\n",
    "Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task.\n",
    "\n",
    "John"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.? \n",
    "\n",
    "Scott"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work\n",
    "\n",
    "You have free reign to provide additional analyses. One idea: grid search parameters in a parallelized fashion and visualize the performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?\n",
    "\n",
    "Scott\n",
    "\n",
    "Possible Analysis:\n",
    "\n",
    "Deep Learning\n",
    "\n",
    "Neaural Network"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
